base_model: "./final_models/mlm-fine-tuned-roberta/checkpoint-1107"
learning_rate: 0.00002
per_device_train_batch_size: 8
per_device_eval_batch_size: 8
num_train_epochs: 3
evaluation_strategy: "epoch"
save_strategy: "epoch"
save_total_limit: 2
logging_dir: "./logs"
load_best_model_at_end: True
output_dir: "./final_models/reduction-regression-roberta-sp"